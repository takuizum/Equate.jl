# LogLinear Transformation

"""
    LogLinearFormula(df::Int64)

Returns GLM formula can be used in `glm` with `FreqTab` data frame.
`df`, is abbreviation for degrees of formula, represents degree of polynomial log-linear method.
This function works very slowly. If a fixed degree formula will be used repeatedly, define the formula as a variable.
"""
function LogLinearFormula(df)
    fml = "@formula(freq ~ 1 +"
    for d in 1:df
        fml *= "scale^$d"
        if d != df
            fml *= " + "
        else
            fml *= ")"
        end
    end
    return eval(Meta.parse(fml))
end

const fmlâ‚ = @formula(freq ~ 1 + scale)
const fmlâ‚‚ = @formula(freq ~ 1 + scale + scale^2)
const fmlâ‚ƒ = @formula(freq ~ 1 + scale + scale^2 + scale^3)
const fmlâ‚„ = @formula(freq ~ 1 + scale + scale^2 + scale^3 + scale^4)
const fmlâ‚… = @formula(freq ~ 1 + scale + scale^2 + scale^3 + scale^4 + scale^5)
const fmlâ‚† = @formula(freq ~ 1 + scale + scale^2 + scale^3 + scale^4 + scale^5 + scale^6)
const fmlâ‚‡ = @formula(freq ~ 1 + scale + scale^2 + scale^3 + scale^4 + scale^5 + scale^6 + scale^7)
const fmlâ‚ˆ = @formula(freq ~ 1 + scale + scale^2 + scale^3 + scale^4 + scale^5 + scale^6 + scale^7 + scale^8)
const fmlâ‚‰ = @formula(freq ~ 1 + scale + scale^2 + scale^3 + scale^4 + scale^5 + scale^6 + scale^7 + scale^8 + scale^9)
const fmlâ‚â‚€ = @formula(freq ~ 1 + scale + scale^2 + scale^3 + scale^4 + scale^5 + scale^6 + scale^7 + scale^8 + scale^9 + scale^10)

struct SmoothedFreqTab <: EG
    table
    raw
    interval
    fit
end
"""
    presmoothing(F::FreqTab, @LogLinearFormula(df::Int64))

Returns presmoothed frequency table as `SmoothedFreqTab` and `glm` fitted object.

Preserving first C moments of original frequency data, passed `LogLinearFormula(C)` to `fml`.
C is a degree of freedom

# Examples
```julia
julia> tab = freqtab(expandtable(ACTmath.scale, ACTmath.xcount));
julia> presmoothing(tab, Equate.fmlâ‚„)
Equate.SmoothedFreqTab(40Ã—5 DataFrame
â”‚ Row â”‚ scale   â”‚ freq     â”‚ cumfreq  â”‚ prob        â”‚ cumprob     â”‚
â”‚     â”‚ Float64 â”‚ Float64? â”‚ Float64? â”‚ Float64     â”‚ Float64     â”‚
â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1   â”‚ 1.0     â”‚ 0.864929 â”‚ 0.864929 â”‚ 0.000199799 â”‚ 0.000199799 â”‚
â”‚ 2   â”‚ 2.0     â”‚ 2.47529  â”‚ 3.34022  â”‚ 0.000571794 â”‚ 0.000771592 â”‚
â‹®
â”‚ 38  â”‚ 38.0    â”‚ 31.9351  â”‚ 4291.07  â”‚ 0.00737703  â”‚ 0.991238    â”‚
â”‚ 39  â”‚ 39.0    â”‚ 22.7842  â”‚ 4313.85  â”‚ 0.00526315  â”‚ 0.996501    â”‚
â”‚ 40  â”‚ 40.0    â”‚ 15.1484  â”‚ 4329.0   â”‚ 0.00349928  â”‚ 1.0         â”‚, [1, 2, 3, 3, 3, 4, 4, 4, 4, 4  â€¦  40, 40, 40, 40, 40, 40, 40, 40, 40, 40], 1.0, StatsModels.TableRegressionModel{GLM.GeneralizedLinearModel{GLM.GlmResp{Array{Float64,1},Distributions.Poisson{Float64},GLM.LogLink},GLM.DensePredChol{Float64,LinearAlgebra.Cholesky{Float64,Array{Float64,2}}}},Array{Float64,2}}

freq ~ 1 + scale + :(scale ^ 2) + :(scale ^ 3) + :(scale ^ 4)

Coefficients:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                   Coef.   Std. Error       z  Pr(>|z|)    Lower 95%    Upper 95%
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
(Intercept)  -1.35982     0.310243      -4.38    <1e-4   -1.96789     -0.751757
scale         1.30127     0.0728808     17.85    <1e-70   1.15843      1.44412
scale ^ 2    -0.089081    0.00589528   -15.11    <1e-50  -0.100636    -0.0775265
scale ^ 3     0.00254824  0.000195003   13.07    <1e-38   0.00216604   0.00293044
scale ^ 4    -2.67698e-5  2.25114e-6   -11.89    <1e-31  -3.1182e-5   -2.23576e-5
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€)

```
"""
function presmoothing(F::EG, fml)
    fit1 = glm(fml, F.table, Poisson(), LogLink())
    freq = predict(fit1, DataFrame(scale = F.table.scale))
    tab = DataFrame(scale = F.table.scale, freq = freq, cumfreq = cumsum(freq),
                    prob = freq ./ sum(freq), cumprob = cumsum(freq) ./ sum(freq))
    return SmoothedFreqTab(tab, F.raw, F.interval, fit1)
end

"""
    presmoothing(F::EG, degree::Int64)
Examine various degree of freedom for fitting the log liner models to the raw score histogram.

# Examples
```julia
julia> tab = freqtab(expandtable(ACTmath.scale, ACTmath.xcount))
Equate.FreqTab(40Ã—5 DataFrame
â”‚ Row â”‚ scale   â”‚ freq  â”‚ cumfreq â”‚ prob       â”‚ cumprob  â”‚
â”‚     â”‚ Float64 â”‚ Int64 â”‚ Int64   â”‚ Float64    â”‚ Float64  â”‚
â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1   â”‚ 1.0     â”‚ 1     â”‚ 1       â”‚ 0.000231   â”‚ 0.000231 â”‚
â”‚ 2   â”‚ 2.0     â”‚ 1     â”‚ 2       â”‚ 0.000231   â”‚ 0.000462 â”‚
â‹®
â”‚ 38  â”‚ 38.0    â”‚ 38    â”‚ 4291    â”‚ 0.00877801 â”‚ 0.991222 â”‚
â”‚ 39  â”‚ 39.0    â”‚ 23    â”‚ 4314    â”‚ 0.00531301 â”‚ 0.996535 â”‚
â”‚ 40  â”‚ 40.0    â”‚ 15    â”‚ 4329    â”‚ 0.003465   â”‚ 1.0      â”‚, [1, 2, 3, 3, 3, 4, 4, 4, 4, 4  â€¦  40, 40, 40, 40, 40, 40, 40, 40, 40, 40], 1.0)

julia> fit = presmoothing(tab, 10)
Fitting dof = 1 model.
Fitting dof = 2 model.
Fitting dof = 3 model.
Fitting dof = 4 model.
Fitting dof = 5 model.
Fitting dof = 6 model.
Fitting dof = 7 model.
Fitting dof = 8 model.
Fitting dof = 9 model.
Fitting dof = 10 model.
10Ã—7 DataFrame. Omitted printing of 1 columns
â”‚ Row â”‚ degree â”‚ aic     â”‚ aicc    â”‚ bic     â”‚ loglik   â”‚ deviance â”‚
â”‚     â”‚ Int64  â”‚ Float64 â”‚ Float64 â”‚ Float64 â”‚ Float64  â”‚ Float64  â”‚
â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1   â”‚ 1      â”‚ 2235.18 â”‚ 2235.5  â”‚ 2238.56 â”‚ -1115.59 â”‚ 1988.28  â”‚
â”‚ 2   â”‚ 2      â”‚ 661.558 â”‚ 662.225 â”‚ 666.625 â”‚ -327.779 â”‚ 412.654  â”‚
â‹®
â”‚ 8   â”‚ 8      â”‚ 290.675 â”‚ 296.675 â”‚ 305.875 â”‚ -136.338 â”‚ 29.7704  â”‚
â”‚ 9   â”‚ 9      â”‚ 292.573 â”‚ 300.159 â”‚ 309.462 â”‚ -136.286 â”‚ 29.6683  â”‚
â”‚ 10  â”‚ 10     â”‚ 294.051 â”‚ 303.48  â”‚ 312.629 â”‚ -136.026 â”‚ 29.1466  â”‚

```
"""
function presmoothing(F::EG, degree::Int64)
    if degree > 11
        throw(ArgumentError("Maximum degree for examining must be less than ore equal to 10."))
    end
    fmls = (fmlâ‚, fmlâ‚‚, fmlâ‚ƒ, fmlâ‚„, fmlâ‚…, fmlâ‚†, fmlâ‚‡, fmlâ‚ˆ, fmlâ‚‰, fmlâ‚â‚€)
    AIC, BIC, AICC, DEVIANCE, LL = zeros.(Float64, fill(degree, 5))
    FIT = Any[]
    for d in 1:degree
        println("Fitting dof = $d model.")
        fit = glm(fmls[d], F.table, Poisson(), LogLink())
        push!(FIT, fit)
        AIC[d] = StatsBase.aic(fit)
        BIC[d] = StatsBase.bic(fit)
        AICC[d] = StatsBase.aicc(fit)
        LL[d] = StatsBase.loglikelihood(fit)
        DEVIANCE[d] = StatsBase.deviance(fit)
    end
    DataFrame(degree = [1:1:degree;], aic = AIC, aicc = AICC, bic = BIC, loglik = LL, deviance = DEVIANCE, fit = FIT)
end

struct SmoothedNEATFreqTab <: NEAT
    tableX
    tableV
    rawX
    rawV
    intervalX
    intervalV
    fitX
    fitV
    marginal
end
"""
    presmoothing(F::NEAT, LogLinearFormula(df::Int64), LogLinearFormula(df::Int64))

Returns presmoothed frequency table as `SmoothedNEATFreqTab` and `glm` fitted object, 
but `interval` and `marginal` elements, which are returned, are not based on smoothed score.

Preserving first C moments of original frequency data, passed `LogLinearFormula(C)` to `fml`.
C is a degree of freedom
"""
function presmoothing(F::NEAT, fmlX, fmlV)
    # Smoothing X (independent part)
    fitX = glm(fmlX, F.tableX, Poisson(), LogLink())
    freqX = predict(fitX, DataFrame(scale = F.tableX.scale))
    tabX = DataFrame(scale = F.tableX.scale, freq = freqX, cumfreq = cumsum(freqX),
                    prob = freqX ./ sum(freqX), cumprob = cumsum(freqX) ./ sum(freqX))
    # Smoothing V (common part)
    fitV = glm(fmlV, F.tableV, Poisson(), LogLink())
    freqV = predict(fitV, DataFrame(scale = F.tableV.scale))
    tabV = DataFrame(scale = F.tableV.scale, freq = freqV, cumfreq = cumsum(freqV),
                    prob = freqV ./ sum(freqV), cumprob = cumsum(freqV) ./ sum(freqV))
    return SmoothedNEATFreqTab(tabX, tabV, F.rawX, F.rawV, F.intervalX, F.intervalV, fitX, fitV, F.marginal)
end


# Kernel method
function RjX(x, xâ±¼, a, Î¼, hX)
    return (x - a * xâ±¼ - (1-a)*Î¼) / (a*hX)
end
struct KernelFreqTab <: EG
    taboe
    raw
    interval
    Bandwidth
end
"""
    KernelSmoothing(X::SmoothedFreqTab; kernel = :Gaussian, hX = 0.622, scale = X.table.scale)

Returns Kernel smoothed frequency table as `KernelFreqTab`.

# Arguments

- `X` the object which class is `freqtab`

## Optional Arguments

- `kernel`
- `hX` The band width.
- `newint` A new interval to depict the continuized probability line.

# Value

`KernelFreqTab`

In the kernel smoothing, the choice of bandwidth `hX` is an important consideration. When bandwidth is large, the smoothed distribution becomes linear equating fucnction. Contrary, bandwidth is small, it becomes spikye shaped distribution. We recommend to use default value `hX = 6.22` or select it by using `EstBandwidth`.
"""
function KernelSmoothing(X::EG; kernel = :Gaussian, hX = 0.622, newint = X.interval/100)
    scale = (minimum(X.table.scale) - X.interval/2):newint:(maximum(X.table.scale) + X.interval/2)
    # hX = bandwidth of cumulative distribution function
    N = sum(X.table.freq)
    Î¼ = mean(X.raw); ÏƒÂ² = var(X.raw)
    aÂ² = ÏƒÂ² / (ÏƒÂ² + hX^2)
    a = sqrt(aÂ²)
    ğ’‡hX = zeros(Float64, length(scale))
    FhX = zeros(Float64, length(scale))
    for (i, x) in enumerate(scale), (j, xâ±¼) in enumerate(X.table.scale)
        ğ’‡hX[i] += X.table.prob[j]*pdf.(Normal(0, 1), RjX(x, xâ±¼, a, Î¼, hX)) / (a*hX)
        FhX[i] += X.table.prob[j]*cdf.(Normal(0, 1), RjX(x, xâ±¼, a, Î¼, hX))
    end
    ğ’‡hX = ğ’‡hX ./ sum(ğ’‡hX) # normalize
    tbl = DataFrame(scale = scale, freq = N .* ğ’‡hX, cunfreq = cumsum(N .* ğ’‡hX), prob = ğ’‡hX, cumprob = cumsum(ğ’‡hX))
    return KernelFreqTab(tbl, X.raw, X.interval, hX)
end

function BandwidthPenalty(hX, X::SmoothedFreqTab, lprob, rprob, K; kernel = :Gaussian)
    hX = exp(hX[1])
    r = X.table.prob
    Î¼ = mean(X.raw); ÏƒÂ² = var(X.raw)
    aÂ² = ÏƒÂ² / (ÏƒÂ² + hX^2)
    a =sqrt(aÂ²)
    ğ’‡hX = zeros(Float64, length(X.table.scale))
    rğ’‡â€²hX = zeros(Float64, length(X.table.scale))
    lğ’‡â€²hX = zeros(Float64, length(X.table.scale))
    for (i, x) in enumerate(X.table.scale), (j, xâ±¼) in enumerate(X.table.scale)
        R = RjX(x, xâ±¼, a, Î¼, hX)
        ğ’‡hX[i] += X.table.prob[j]*pdf.(Normal(0, 1), R) / (a*hX)
        rğ’‡â€²hX[i] -= rprob[j]*pdf.(Normal(0, 1), R) / (a*hX)^2 * R
        lğ’‡â€²hX[i] -= lprob[j]*pdf.(Normal(0, 1), R) / (a*hX)^2 * R
    end
    pen1 = sum((r .- ğ’‡hX) .^2)
    pen2 = sum((lğ’‡â€²hX .< 0) .* (rğ’‡â€²hX .> 0))
    return pen1 + K * pen2
end

"""
    EstBandwidth(X::EG; kernel = :Gaussian)

Estimate optimal bandwidth `hX` in Gaussian kernel.

# Arguments

- `X` is the object which the class is `freqtab`.

# Value

Optimize information.

"""
function EstBandwidth(X::SmoothedFreqTab; kernel = :Gaussian, K = 1)
    x = X.table.scale
    lscore = x .- X.interval/4
    rscore = x .+ X.interval/4
    lpred = predict(X.fit, DataFrame(scale = lscore))
    rpred = predict(X.fit, DataFrame(scale = rscore))
    opt = optimize(hX -> BandwidthPenalty(hX, X, lpred, rpred, K; kernel = kernel), [0.5], method = BFGS())
    println("Minimizer sould be transformed `exp()` before interpretation. \nMinimizer (after taking `exp()`) = $(exp(opt.minimizer[1]))\n\n")
    return opt
end
