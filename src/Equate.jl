module Equate

using DataFrames, Statistics, GLM, Distributions, Optim

export freqtab, round2, PRF, CDF, PFu, PFl, Equipercentile, presmoothing, Linear, Tucker, ChainedLinear, ObservableStats, FrequencyEstimation, KernelSmoothing, BandwidthPenalty, EstBandwidth, BraunHolland, ChainedEquipercentile
export LogLinearFormula

abstract type EquateDesign end
abstract type EG <: EquateDesign end
abstract type NEAT <: EquateDesign end
# non equivalent common item design
struct FreqTab <: EG
    tab::DataFrame
    raw::Vector
    interval::Float64
end
# Frequaency table for equivalent group design
function freqtab(X; interval = 1.0, scale = minimum(X):interval:maximum(X))
    freq = map(j -> count(i -> i == j, X), scale)
    cumfreq = cumsum(freq)
    cumprob = cumsum(freq) ./ sum(freq)
    res = DataFrame(scale = scale, freq = freq, cumfreq = cumfreq, prob = freq ./ sum(freq), cumprob = cumprob)
    return FreqTab(res, X, interval)
end

# Equate method
abstract type SGEquateMethod end
# Natural Round
round2(x; digits = 0) = sign(x) * floor( abs(x) * 10.0^digits + 0.5 ) / (10.0^digits)
# Percentile Rank Function
function CDF(x, F::EG)
    if x < minimum(F.tab.scale) return 0 end
    if x > maximum(F.tab.scale) return 1 end
    F.tab.cumprob[F.tab.scale .== x][1]
end
function PRF(x, F::EG)
    if x < (minimum(F.tab.scale) - F.interval/2.0) return 0.0 end
    if x â‰¥ (maximum(F.tab.scale) + F.interval/2.0) return 100.0 end
    xâ€² = round2(x)
    Fx1 = CDF(xâ€²-F.interval, F)#F.tab.cumfreq[F.tab.scale .== (xâƒ°-1.0)]
    Fx = CDF(xâ€², F)#F.tab.cumfreq[F.tab.scale .== xâƒ°]
    P = 100*(Fx1+(x-xâ€²+F.interval/2.0)*(Fx-Fx1))[1]
    return P
end
# Percentile Function
function p_search_descend(P, F::EG, offset)
    x = nothing;iter = length(F.tab.scale)
    while x == nothing
        iter -= 1
        x =  100CDF(F.tab.scale[iter], F) > P ? nothing : F.tab.scale[iter+offset]
    end
    return x
end
function p_search_ascend(P, F::EG, offset)
    x = nothing;iter = 0
    while x == nothing
        iter += 1
        x = 100CDF(F.tab.scale[iter], F) < P ? nothing : iter == 1 ? 0.0 : F.tab.scale[iter+offset]
    end
    return x
end
function PFu(P, F::EG)
    if P â‰¥ 100.0 return (maximum(F.tab.scale) + .5) end
    xu = P > 50.0 ? p_search_descend(P, F, 1) : p_search_ascend(P, F, 0)
    x = (P/100 - CDF(xu-F.interval, F)) / (CDF(xu, F) - CDF(xu-F.interval, F))
    return isinf(x) || isnan(x) ? xu -F.interval/2.0 : x + xu -F.interval/2.0
end
function PFl(P, F::EG)
    if P â‰¤ 0.0 return -.5 end
    xl = P > 50.0 ? p_search_descend(P, F, 0) : p_search_ascend(P, F, -1)
    x = (P/100 - CDF(xl, F)) / (CDF(xl+F.interval, F) - CDF(xl, F))
    return isinf(x) ? xl + F.interval/2.0 : x + xl + F.interval/2.0
end
# equipercentile equating
struct ResultEquipercentile <: SGEquateMethod
    table::DataFrame
end
function Equipercentile(X::EG, Y::EG; case = :middle)
    scaleY = Y.tab.scale
    eYxu = zeros(Float64, length(scaleY)); eYxl = zeros(Float64, length(scaleY))
    for (i,v) in enumerate(scaleY)
        P = PRF(v, Y)
        eYxu[i] = PFu(P, X)
        eYxl[i] = PFl(P, X)
    end
    if case == :upper
        eYx = eYxu
    elseif case == :lower
        eYx = eYxl
    elseif case == :both
        eYx = string.(eYxu, "_", eYxl)
    elseif case == :middle
        eYx = (eYxu .+ eYxl) ./ 2.0
    end
    tbl = DataFrame(scaleY = scaleY, eYx = eYx)
    return ResultEquipercentile(tbl)
end
# linear equating
struct ResultLinear <: SGEquateMethod
    table::DataFrame
end
function Linear(X::EG, Y::EG)
    Î¼X = mean(X.raw); ÏƒX = std(X.raw)
    Î¼Y = mean(Y.raw); ÏƒY = std(Y.raw)
    slope = ÏƒY/ÏƒX; intercept = Î¼Y - slope*Î¼X
    eYx = @. X.tab.scale * slope + intercept
    tbl = DataFrame(scaleX = X.tab.scale, eYx = eYx)
    ResultLinear(tbl)
end
# LogLinear Transformation
function LogLinearFormula(df)
    fml = "@formula(freq ~ 1 +"
    for d in 1:df
        fml *= "scale^$d"
        if d != df
            fml *= " + "
        else
            fml *= ")"
        end
    end
    return eval(Meta.parse(fml))
end
struct SmoothedFreqTab <: EG
    tab::DataFrame
    raw::Vector
    interval::Float64
end
function presmoothing(F::FreqTab; fml = LogLinearFormula(4))
    fit1 = glm(fml, F.tab, Poisson(), LogLink())
    pred = predict(fit1, DataFrame(scale = F.tab.scale))
    tab = DataFrame(scale = F.tab.scale, prob = pred, cumprob = cumsum(pred))
    return SmoothedFreqTab(tab, F.raw, F.interval), fit1
end
# Kernel method
function RjX(x, xâ±¼, a, Î¼, hX)
    return (x - a * xâ±¼ - (1-a)*Î¼) / (a*hX)
end
struct KernelFreqTab <: EG
    tab::DataFrame
    raw::Vector
    interval::Float64
    Bandwidth::Float64
end
function KernelSmoothing(X::EG; kernel = :Gaussian, hX = 0.66, scale = X.tab.scale)
    # hX = bandwidht of cumulative distribution function
    Î¼ = mean(X.raw); ÏƒÂ² = var(X.raw)
    aÂ² = ÏƒÂ² / (ÏƒÂ² + hX^2)
    a =sqrt(aÂ²)
    ð’‡hX = zeros(Float64, length(scale))
    FhX = zeros(Float64, length(scale))
    for (i, x) in enumerate(scale), (j, xâ±¼) in enumerate(X.tab.scale)
        ð’‡hX[i] += X.tab.prob[j]*pdf.(Normal(0, 1), RjX(x, xâ±¼, a, Î¼, hX)) / (a*hX)
        FhX[i] += X.tab.prob[j]*cdf.(Normal(0, 1), RjX(x, xâ±¼, a, Î¼, hX))
    end
    tbl = DataFrame(scale = scale, prob = ð’‡hX, cumprob = cumsum(ð’‡hX))
    return KernelFreqTab(tbl, X.raw, X.interval, hX)
end
function BandwidthPenalty(hX, X::EG; kernel = :Gaussian)
    hX = exp(hX[1])
    r = X.tab.prob
    Î¼ = mean(X.raw); ÏƒÂ² = var(X.raw)
    aÂ² = ÏƒÂ² / (ÏƒÂ² + hX^2)
    a =sqrt(aÂ²)
    ð’‡hX = zeros(Float64, length(X.tab.scale))
    ð’‡â€²hX = zeros(Float64, length(X.tab.scale))
    for (i, x) in enumerate(X.tab.scale), (j, xâ±¼) in enumerate(X.tab.scale)
        R = RjX(x, xâ±¼, a, Î¼, hX)
        ð’‡hX[i] += X.tab.prob[j]*pdf.(Normal(0, 1), R) / (a*hX)
        ð’‡â€²hX[i] -= X.tab.prob[j]*pdf.(Normal(0, 1), R) / (a*hX)^2 * R
    end
    pen1 = sum((r .- ð’‡hX) .^2)
    return pen1
end
function EstBandwidth(X::EG; kernel = :Gaussian)
    opt = optimize(hX -> BandwidthPenalty(hX, X), [0.5], method = BFGS())
    println("Minimizer sould be transformed `exp()` before interpretation. Minimizer = $(exp(opt.minimizer[1]))")
    return opt
end


# equivalent group design
abstract type NEATEquateMethod end
struct SGFreqTab <: NEAT
    tabX::DataFrame
    tabV::DataFrame
    rawX::Vector # independent form
    rawV::Vector # common form
    intervalX::Float64
    intervalV::Float64
    marginal::Matrix # conditional freqency
end
# Frequency table for nonequivalent gtoup design
function freqtab(X, V;intervalX = 1.0, intervalV = 1.0, scaleX = minimum(X):intervalX:maximum(X), scaleV = minimum(V):intervalV:maximum(V))
    if length(X) != length(V)
        println("X and V must be same length(test scores of which the same group).")
    end
    freqx = map(j -> count(i -> i == j, X), scaleX)
    cumprobx = cumsum(freqx)./ sum(freqx)
    freqv = map(j -> count(i -> i == j, V), scaleV)
    cumprobv = cumsum(freqv)./ sum(freqv)
    tabX = DataFrame(scale = scaleX, freq = freqx, cumprob = cumprobx, prob = freqx ./ sum(freqx))
    tabV = DataFrame(scale = scaleV, freq = freqv, cumprob = cumprobv, prob = freqv ./ sum(freqv))
    marginaltable = zeros(Int64, length(scaleX), length(scaleV))
    for (xi, xv) in enumerate(scaleX), (vi, vv) in enumerate(scaleV)
        marginaltable[xi,vi] = count(i -> i == vv, V[X .== xv])
    end
    return SGFreqTab(tabX, tabV, X, V, intervalX, intervalV, marginaltable)
end
# Nonequivalent Groups : Linear methods
function ObservableStats(F::NEAT)
    x = F.rawX; v = F.rawV
    Î¼x = mean(x); Ïƒx = std(x)
    Î¼v = mean(v); Ïƒv = std(v)
    covxv = cov(x, v); corxv = cor(x, v)
    return Î¼x, Ïƒx, Î¼v, Ïƒv, covxv, corxv
end
struct ResultTucker <: NEATEquateMethod
    table::DataFrame
    synthetic::DataFrame
    estimates::NamedTuple
end
function Tucker(X::NEAT, Y::NEAT; wâ‚ = length(X.rawX) / (length(X.rawX) + length(Y.rawX)), wâ‚‚ = 1.0 - wâ‚)
    W = wâ‚ + wâ‚‚
    wâ‚ = wâ‚ / W; wâ‚‚ = wâ‚‚ / W
    # test score
    x = X.rawX; xv = X.rawV
    y = Y.rawX; yv = Y.rawV
    # ObservableStats
    Î¼x, Ïƒx, Î¼xv, Ïƒxv, covxv, corxv = ObservableStats(X)
    Î¼y, Ïƒy, Î¼yv, Ïƒyv, covyv, coryv = ObservableStats(Y)
    # regression slope
    Î³â‚ = covxv / Ïƒxv^2
    Î³â‚‚ = covyv / Ïƒyv^2
    # synthetic mean and var
    Î¼sX = Î¼x - wâ‚‚*Î³â‚*(Î¼xv-Î¼yv)
    Î¼sY = Î¼y + wâ‚*Î³â‚‚*(Î¼xv-Î¼yv)
    ÏƒÂ²sX = Ïƒx^2 - wâ‚‚*Î³â‚^2*(Ïƒxv^2-Ïƒyv^2) + wâ‚*wâ‚‚*Î³â‚^2*(Î¼xv-Î¼yv)^2
    ÏƒÂ²sY = Ïƒy^2 + wâ‚*Î³â‚‚^2*(Ïƒxv^2-Ïƒyv^2) + wâ‚*wâ‚‚*Î³â‚‚^2*(Î¼xv-Î¼yv)^2
    # transformation
    slope = sqrt(ÏƒÂ²sY)/sqrt(ÏƒÂ²sX); intercept = Î¼sY - slope*Î¼sX
    lYx = @. X.tabX.scale * slope + intercept
    tbl = DataFrame(scaleX = X.tabX.scale, lYx = lYx)
    return ResultTucker(tbl,
                       DataFrame(Group = [1, 2], Î¼ = [Î¼sX, Î¼sY], Ïƒ = [sqrt(ÏƒÂ²sX), sqrt(ÏƒÂ²sY)], Î³ = [Î³â‚, Î³â‚‚], w = [wâ‚, wâ‚‚]),
                       (slope = slope, intercept = intercept))
end
# Nonequivalent Goups : Chained linear Observed Score Equating
struct ResultChainedLinear <: NEATEquateMethod
    table::DataFrame
    synthetic::DataFrame
    estimates::NamedTuple
end
function ChainedLinear(X::NEAT, Y::NEAT)
    # ******************************************** #
    # 1. put X on the scale of V -call lV(x);
    # 2. put V on the scale of Y - call lY(v);
    # 3. obtain Y-equivalent as lY(x).
    # ******************************************** #
    # test score
    x = X.rawX; xv = X.rawV
    y = Y.rawX; yv = Y.rawV
    # ObservableStats
    Î¼x, Ïƒx, Î¼xv, Ïƒxv, covxv, corxv = ObservableStats(X)
    Î¼y, Ïƒy, Î¼yv, Ïƒyv, covyv, coryv = ObservableStats(Y)
    # regression slope
    Î³â‚ = Ïƒx / Ïƒxv
    Î³â‚‚ = Ïƒy / Ïƒyv
    # estimate
    slope = (Ïƒy/Ïƒyv)/(Ïƒx/Ïƒxv)
    intercept = Î¼y + Ïƒy/Ïƒyv *(Î¼xv - Î¼yv) - slope * Î¼x
    lYx = @. X.tabX.scale * slope + intercept
    tbl =  DataFrame(scaleX = X.tabX.scale, lYx = lYx)
    ResultChainedLinear(tbl,
                        DataFrame(Group = [1,2], Î³ = [Î³â‚, Î³â‚‚]),
                        (slope = slope, intercept = intercept))
end
# Nonequivalent Goups : Frequency Estimation
struct ResultFrequencyEstimation <: NEATEquateMethod
    table::DataFrame
    marginalX::Matrix
    marginalY::Matrix
end
function FrequencyEstimation(X::NEAT, Y::NEAT; wâ‚ = length(X.rawX) / (length(X.rawX) + length(Y.rawX)), wâ‚‚ = 1.0 - wâ‚)
    # synthetic weight
    W = wâ‚ + wâ‚‚
    wâ‚ = wâ‚ / W; wâ‚‚ = wâ‚‚ / W
    # prior (the weights from common part)
    J = length(X.tabV.freq)
    hâ‚ = X.tabV.freq / sum(X.tabV.freq)
    hâ‚‚ = Y.tabV.freq / sum(Y.tabV.freq)
    fâ‚‚x = zeros(Float64, length(X.tabX.freq))
    gâ‚y = zeros(Float64, length(Y.tabX.freq))
    for j in 1:length(X.tabX.scale)
        fâ‚‚x[j] = X.marginal[j,:]' * hâ‚‚
    end
    for j in 1:length(Y.tabX.scale)
        gâ‚y[j] = Y.marginal[j,:]' * hâ‚
    end
    # synthetic population
    fsx = @. wâ‚ * X.tabX.freq + wâ‚‚ * fâ‚‚x
    fsy = @. wâ‚ * gâ‚y + wâ‚‚ * Y.tabX.freq
    # Equipercentile Equating
    ftX = FreqTab(DataFrame(scale = X.tabX.scale, freq = fsx, cumprob = cumsum(fsx) ./ sum(fsx)),
                  X.rawX, X.intervalX)
    ftY = FreqTab(DataFrame(scale = Y.tabX.scale, freq = fsy, cumprob = cumsum(fsy) ./ sum(fsy)),
                  Y.rawX, Y.intervalX)
    tbl = equipercentile(ftX, ftY)
    return ResultFrequencyEstimation(tbl, X.marginal, Y.marginal)
end
# Nonequivalent Groups : Braun-Holland Linear Method
struct ResultBraunHolland <: NEATEquateMethod
    table::DataFrame
    marginalX::Matrix
    marginalY::Matrix
end
function BraunHolland(X::NEAT, Y::NEAT; wâ‚ = length(X.rawX) / (length(X.rawX) + length(Y.rawX)), wâ‚‚ = 1.0 - wâ‚)
    # synthetic weight
    W = wâ‚ + wâ‚‚
    wâ‚ = wâ‚ / W; wâ‚‚ = wâ‚‚ / W
    # prior (the weights from common part)
    J = length(X.tabV.freq)
    hâ‚ = X.tabV.freq / sum(X.tabV.freq)
    hâ‚‚ = Y.tabV.freq / sum(Y.tabV.freq)
    fâ‚‚x = zeros(Float64, length(X.tabX.freq))
    gâ‚y = zeros(Float64, length(Y.tabX.freq))
    for j in 1:length(X.tabX.scale)
        fâ‚‚x[j] = X.marginal[j,:]' * hâ‚‚
    end
    for j in 1:length(Y.tabX.scale)
        gâ‚y[j] = Y.marginal[j,:]' * hâ‚
    end
    # synthetic population
    fsx = @. wâ‚ * X.tabX.freq + wâ‚‚ * fâ‚‚x; fsx = fsx ./ sum(fsx)
    fsy = @. wâ‚ * gâ‚y + wâ‚‚ * Y.tabX.freq; fsy = fsy ./ sum(fsy)
    # synthetic pupulation parameter
    Î¼sx = fsx' * X.tabX.scale; Ïƒsx = sqrt(fsx' * (X.tabX.scale .- Î¼sx) .^2)
    Î¼sy = fsy' * Y.tabX.scale; Ïƒsy = sqrt(fsy' * (Y.tabX.scale .- Î¼sy) .^2)
    Î¼xv = mean(X.rawV); Ïƒxv = std(X.rawV)
    Î¼yv = mean(Y.rawV); Ïƒyv = std(Y.rawV)
    # internal regression parameter
    Î³â‚ = Ïƒsx / Ïƒxv; Î³â‚‚ = Ïƒsy / Ïƒyv
    # external regression parameter
    slope = Î³â‚‚ / Î³â‚; intercept = Î¼sy + Ïƒsy/Ïƒyv*(Î¼xv-Î¼yv) - slope * Î¼sx
    lYx = @. X.tabX.scale * slope + intercept
    tbl = DataFrame(scaleX = X.tabX.scale, lYx = lYx)
    return ResultBraunHolland(tbl, X.marginal, Y.marginal)
end

# Nonequivalent Groups : Chained Equipercentile Method
struct ResultChainedEquipercentile <: NEATEquateMethod
    table::DataFrame
end
function ChainedEquipercentile(X::NEAT, Y::NEAT; case = :middle)
    #
    ftX = freqtab(X.rawX); ftXV = freqtab(X.rawV)
    eVâ‚ = Equipercentile(ftX, ftXV)
    eYâ‚‚ = Equipercentile(freqtab(Y.rawV), freqtab(Y.rawX))
    # Search percentile of score V on scale Y
    eYxu = zeros(Float64, length(eYâ‚‚.table.scaleY)); eYxl = zeros(Float64, length(eYâ‚‚.table.scaleY))
    for (i,v) in enumerate(eYâ‚‚.table.eYx)
        P = PRF(v, ftXV)
        eYxu[i] = PFu(P, ftX)
        eYxl[i] = PFl(P, ftX)
    end
    if case == :upper
        eYx = eYxu
    elseif case == :lower
        eYx = eYxl
    elseif case == :both
        eYx = string.(eYxu, "_", eYxl)
    elseif case == :middle
        eYx = (eYxu .+ eYxl) ./ 2.0
    end
    tbl = DataFrame(scaleY = eYâ‚‚.table.scaleY, eYx = eYx)
    return ResultChainedEquipercentile(tbl)
end
#-----------------
end # module
