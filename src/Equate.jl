module Equate

using DataFrames, Statistics, GLM, Distributions, Optim

export freqtab, round2, PRF, CDF, PFu, PFl, equipercentile, presmoothing, linear, Tucker, ChainedLinear, ObservableStats, FrequencyEstimation, KernelSmoothing, BandwidthPenalty, EstBandwidth
export LogLinearFormula

abstract type EquateDesign end
abstract type EGD <: EquateDesign end
abstract type NGD <: EquateDesign end
# non equivalent common item design
struct FreqTab <: EGD
    tab::DataFrame
    raw::Vector
    interval::Float64
end
# Frequaency table for equivalent group design
function freqtab(X; interval = 1.0, scale = minimum(X):interval:maximum(X))
    freq = map(j -> count(i -> i == j, X), scale)
    cumfreq = cumsum(freq)
    cumprob = cumsum(freq) ./ sum(freq)
    res = DataFrame(scale = scale, freq = freq, cumfreq = cumfreq, prob = freq ./ sum(freq), cumprob = cumprob)
    return FreqTab(res, X, interval)
end

# Equate method
abstract type EquateMethod end
struct Equipercentile <:EquateMethod end
struct Linear <: EquateMethod end
# Natural Round
round2(x; digits = 0) = sign(x) * floor( abs(x) * 10.0^digits + 0.5 ) / (10.0^digits)
# Percentile Rank Function
function CDF(x, F::FreqTab)
    if x < minimum(F.tab.scale) return 0 end
    if x > maximum(F.tab.scale) return 1 end
    F.tab.cumprob[F.tab.scale .== x][1]
end
function PRF(x, F::FreqTab)
    if x < (minimum(F.tab.scale) - F.interval/2.0) return 0.0 end
    if x ‚â• (maximum(F.tab.scale) + F.interval/2.0) return 100.0 end
    x‚Ä≤ = round2(x)
    Fx1 = CDF(x‚Ä≤-F.interval, F)#F.tab.cumfreq[F.tab.scale .== (x‚É∞-1.0)]
    Fx = CDF(x‚Ä≤, F)#F.tab.cumfreq[F.tab.scale .== x‚É∞]
    P = 100*(Fx1+(x-x‚Ä≤+F.interval/2.0)*(Fx-Fx1))[1]
    return P
end
# Percentile Function
function p_search_descend(P, F::FreqTab, offset)
    x = nothing;iter = length(F.tab.scale)
    while x == nothing
        iter -= 1
        x =  100CDF(F.tab.scale[iter], F) > P ? nothing : F.tab.scale[iter+offset]
    end
    return x
end
function p_search_ascend(P, F::FreqTab, offset)
    x = nothing;iter = 0
    while x == nothing
        iter += 1
        x = 100CDF(F.tab.scale[iter], F) < P ? nothing : iter == 1 ? 0.0 : F.tab.scale[iter+offset]
    end
    return x
end
function PFu(P, F::FreqTab)
    if P ‚â• 100.0 return (maximum(F.tab.scale) + .5) end
    xu = P > 50.0 ? p_search_descend(P, F, 1) : p_search_ascend(P, F, 0)
    x = (P/100 - CDF(xu-F.interval, F)) / (CDF(xu, F) - CDF(xu-F.interval, F))
    return isinf(x) || isnan(x) ? xu -F.interval/2.0 : x + xu -F.interval/2.0
end
function PFl(P, F::FreqTab)
    if P ‚â§ 0.0 return -.5 end
    xl = P > 50.0 ? p_search_descend(P, F, 0) : p_search_ascend(P, F, -1)
    x = (P/100 - CDF(xl, F)) / (CDF(xl+F.interval, F) - CDF(xl, F))
    return isinf(x) ? xl + F.interval/2.0 : x + xl + F.interval/2.0
end
# equipercentile equating
function equipercentile(X::FreqTab, Y::FreqTab; case = :middle)
    scaleY = Y.tab.scale
    eYxu = zeros(Float64, length(scaleY)); eYxl = zeros(Float64, length(scaleY))
    for (i,v) in enumerate(scaleY)
        P = PRF(v, X)
        eYxu[i] = PFu(P, Y)
        eYxl[i] = PFl(P, Y)
    end
    if case == :upper
        eYx = eYxu
    elseif case == :lower
        eYx = eYxl
    elseif case == :both
        eYx = string.(eYxu, "_", eYxl)
    elseif case == :middle
        eYx = (eYxu .+ eYxl) ./ 2.0
    end
    return DataFrame(scaleY = scaleY, eYx = eYx)
end
# linear equating
function linear(X::FreqTab, Y::FreqTab)
    ŒºX = mean(X.raw); œÉX = std(X.raw)
    ŒºY = mean(Y.raw); œÉY = std(Y.raw)
    slope = œÉY/œÉX; intercept = ŒºY - slope*ŒºX
    eYx = @. X.tab.scale * slope + intercept
    return DataFrame(scaleX = X.tab.scale, eYx = eYx)
end
# LogLinear Transformation
function LogLinearFormula(df)
    fml = "@formula(freq ~ 1 +"
    for d in 1:df
        fml *= "scale^$d"
        if d != df
            fml *= " + "
        else
            fml *= ")"
        end
    end
    return eval(Meta.parse(fml))
end
function presmoothing(F::FreqTab; fml = LogLinearFormula(4))
    fit1 = glm(fml, F.tab, Poisson(), LogLink())
    pred = predict(fit1, DataFrame(scale = F.tab.scale))
    tab = DataFrame(scale = F.tab.scale, prob = pred, cumprob = cumsum(pred))
    return FreqTab(tab, F.raw, F.interval), fit1
end
# Kernel method
function RjX(x, x‚±º, a, Œº, hX)
    return (x - a * x‚±º - (1-a)*Œº) / (a*hX)
end
struct KernelFreqTab
    tab::DataFrame
    raw::Vector
    interval::Float64
end
function KernelSmoothing(X::FreqTab; kernel = :Gaussian, hX = 0.66, scale = X.tab.scale)
    # hX = bandwidht of cumulative distribution function
    Œº = mean(X.raw); œÉ¬≤ = var(X.raw)
    a¬≤ = œÉ¬≤ / (œÉ¬≤ + hX^2)
    a =sqrt(a¬≤)
    ùíáhX = zeros(Float64, length(scale))
    FhX = zeros(Float64, length(scale))
    for (i, x) in enumerate(scale), (j, x‚±º) in enumerate(X.tab.scale)
        ùíáhX[i] += X.tab.prob[j]*pdf.(Normal(0, 1), RjX(x, x‚±º, a, Œº, hX)) / (a*hX)
        FhX[i] += X.tab.prob[j]*cdf.(Normal(0, 1), RjX(x, x‚±º, a, Œº, hX))
    end
    tbl = DataFrame(scale = scale, prob = ùíáhX, cumprob = cumsum(ùíáhX))
    return KernelFreqTab(tbl, X.raw, X.interval)
end
function BandwidthPenalty(hX, X::FreqTab; kernel = :Gaussian)
    hX = exp(hX[1])
    r = X.tab.prob
    Œº = mean(X.raw); œÉ¬≤ = var(X.raw)
    a¬≤ = œÉ¬≤ / (œÉ¬≤ + hX^2)
    a =sqrt(a¬≤)
    ùíáhX = zeros(Float64, length(X.tab.scale))
    ùíá‚Ä≤hX = zeros(Float64, length(X.tab.scale))
    for (i, x) in enumerate(X.tab.scale), (j, x‚±º) in enumerate(X.tab.scale)
        R = RjX(x, x‚±º, a, Œº, hX)
        ùíáhX[i] += X.tab.prob[j]*pdf.(Normal(0, 1), R) / (a*hX)
        ùíá‚Ä≤hX[i] -= X.tab.prob[j]*pdf.(Normal(0, 1), R) / (a*hX)^2 * R
    end
    pen1 = sum((r .- ùíáhX) .^2)
    return pen1
end
function EstBandwidth(X::FreqTab; kernel = :Gaussian)
    opt = optimize(hX -> BandwidthPenalty(hX, X), [0.5], method = BFGS())
    println("Minimizer sould be transformed `exp()` before interpretation. Minimizer = $(exp(opt.minimizer[1]))")
    return opt
end


# equivalent group design
struct SGFreqTab <: NGD
    tabX::DataFrame
    tabV::DataFrame
    rawX::Vector # independent form
    rawV::Vector # common form
    intervalX::Float64
    intervalV::Float64
    marginal::Matrix # conditional freqency
end
# Frequency table for nonequivalent gtoup design
function freqtab(X, V;intervalX = 1.0, intervalV = 1.0, scaleX = minimum(X):intervalX:maximum(X), scaleV = minimum(V):intervalV:maximum(V))
    if length(X) != length(V)
        println("X and V must be same length(test scores of which the same group).")
    end
    freqx = map(j -> count(i -> i == j, X), scaleX)
    cumprobx = cumsum(freqx)./ sum(freqx)
    freqv = map(j -> count(i -> i == j, V), scaleV)
    cumprobv = cumsum(freqv)./ sum(freqv)
    tabX = DataFrame(scale = scaleX, freq = freqx, cumprob = cumprobx, prob = freqx ./ sum(freqx))
    tabV = DataFrame(scale = scaleV, freq = freqv, cumprob = cumprobv, prob = freqv ./ sum(freqv))
    marginaltable = zeros(Int64, length(scaleX), length(scaleV))
    for (xi, xv) in enumerate(scaleX), (vi, vv) in enumerate(scaleV)
        marginaltable[xi,vi] = count(i -> i == vv, V[X .== xv])
    end
    return SGFreqTab(tabX, tabV, X, V, intervalX, intervalV, marginaltable)
end
# Nonequivalent Groups : Linear methods
function ObservableStats(F::SGFreqTab)
    x = F.rawX; v = F.rawV
    Œºx = mean(x); œÉx = std(x)
    Œºv = mean(v); œÉv = std(v)
    covxv = cov(x, v); corxv = cor(x, v)
    return Œºx, œÉx, Œºv, œÉv, covxv, corxv
end
struct resTucker
    table::DataFrame
    synsetic::DataFrame
    estimates::NamedTuple
end
function Tucker(X::SGFreqTab, Y::SGFreqTab; w‚ÇÅ = length(X.rawX) / (length(X.rawX) + length(Y.rawX)), w‚ÇÇ = 1.0 - w‚ÇÅ)
    W = w‚ÇÅ + w‚ÇÇ
    w‚ÇÅ = w‚ÇÅ / W; w‚ÇÇ = w‚ÇÇ / W
    # test score
    x = X.rawX; xv = X.rawV
    y = Y.rawX; yv = Y.rawV
    # ObservableStats
    Œºx, œÉx, Œºxv, œÉxv, covxv, corxv = ObservableStats(X)
    Œºy, œÉy, Œºyv, œÉyv, covyv, coryv = ObservableStats(Y)
    # regression slope
    Œ≥‚ÇÅ = cov(x,xv) / var(xv)
    Œ≥‚ÇÇ = cov(y,yv) / var(yv)
    # synsetic mean and var
    ŒºsX = Œºx - w‚ÇÇ*Œ≥‚ÇÅ*(Œºxv-Œºyv)
    ŒºsY = Œºy + w‚ÇÅ*Œ≥‚ÇÇ*(Œºxv-Œºyv)
    œÉ¬≤sX = œÉx^2 - w‚ÇÇ*Œ≥‚ÇÅ^2*(œÉxv^2-œÉyv^2) + w‚ÇÅ*w‚ÇÇ*Œ≥‚ÇÅ^2*(Œºxv-Œºyv)^2
    œÉ¬≤sY = œÉy^2 + w‚ÇÅ*Œ≥‚ÇÇ^2*(œÉxv^2-œÉyv^2) + w‚ÇÅ*w‚ÇÇ*Œ≥‚ÇÇ^2*(Œºxv-Œºyv)^2
    # transformation
    slope = sqrt(œÉ¬≤sY)/sqrt(œÉ¬≤sX); intercept = ŒºsY - slope*ŒºsX
    eYx = @. X.tabX.scale * slope + intercept
    tbl = DataFrame(scaleX = X.tabX.scale, eYx = eYx)
    return resTucker(tbl,
                     DataFrame(Group = [1, 2], Œº = [ŒºsX, ŒºsY], œÉ = [sqrt(œÉ¬≤sX), sqrt(œÉ¬≤sY)], Œ≥ = [Œ≥‚ÇÅ, Œ≥‚ÇÇ], w = [w‚ÇÅ, w‚ÇÇ]),
                     (slope = slope, intercept = intercept))
end
# Nonequivalent Goups : Chained linear Observed Score Equating
struct resChainedLinear
    table::DataFrame
    synsetic::DataFrame
    estimates::NamedTuple
end
function ChainedLinear(X::SGFreqTab, Y::SGFreqTab)
    # ******************************************** #
    # 1. put X on the scale of V -call lV(x);
    # 2. put V on the scale of Y - call lY(v);
    # 3. obtain Y-equivalent as lY(x).
    # ******************************************** #
    # test score
    x = X.rawX; xv = X.rawV
    y = Y.rawX; yv = Y.rawV
    # ObservableStats
    Œºx, œÉx, Œºxv, œÉxv, covxv, corxv = ObservableStats(X)
    Œºy, œÉy, Œºyv, œÉyv, covyv, coryv = ObservableStats(Y)
    # regression slope
    Œ≥‚ÇÅ = covxv / œÉxv^2
    Œ≥‚ÇÇ = covyv / œÉyv^2
    # estimate
    slope = (œÉy/œÉyv)/(œÉx/œÉxv)
    intercept = Œºy + œÉy/œÉyv *(Œºxv - Œºyv) - slope * Œºx
    eYx = @. X.tabX.scale * slope + intercept
    tbl =  DataFrame(scaleX = X.tabX.scale, eYx = eYx)
    resChainedLinear(tbl,
                     DataFrame(Group = [1,2], Œ≥ = [Œ≥‚ÇÅ, Œ≥‚ÇÇ]),
                     (slope = slope, intercept = intercept))
end
# Nonequivalent Goups : Frequency Estimation
struct resFrequencyEstimation
    table::DataFrame
    marginalX::Matrix
    marginalY::Matrix
end
function FrequencyEstimation(X::SGFreqTab, Y::SGFreqTab; w‚ÇÅ = length(X.rawX) / (length(X.rawX) + length(Y.rawX)), w‚ÇÇ = 1.0 - w‚ÇÅ)
    # synsetic weight
    W = w‚ÇÅ + w‚ÇÇ
    w‚ÇÅ = w‚ÇÅ / W; w‚ÇÇ = w‚ÇÇ / W
    # prior (the weights from common part)
    J = length(X.tabV.freq)
    h‚ÇÅ = X.tabV.freq / sum(X.tabV.freq)
    h‚ÇÇ = Y.tabV.freq / sum(Y.tabV.freq)
    f‚ÇÇx = zeros(Float64, length(X.tabX.freq))
    g‚ÇÅy = zeros(Float64, length(Y.tabX.freq))
    for j in 1:length(X.tabX.scale)
        f‚ÇÇx[j] = X.marginal[j,:]' * h‚ÇÇ
    end
    for j in 1:length(Y.tabX.scale)
        g‚ÇÅy[j] = Y.marginal[j,:]' * h‚ÇÅ
    end
    # synsetic population
    fsx = @. w‚ÇÅ * X.tabX.freq + w‚ÇÇ * f‚ÇÇx
    fsy = @. w‚ÇÅ * g‚ÇÅy + w‚ÇÇ * Y.tabX.freq
    # Equipercentile Equating
    ftX = FreqTab(DataFrame(scale = X.tabX.scale, freq = fsx, cumprob = cumsum(fsx) ./ sum(fsx)),
                  X.rawX, X.intervalX)
    ftY = FreqTab(DataFrame(scale = Y.tabX.scale, freq = fsy, cumprob = cumsum(fsy) ./ sum(fsy)),
                  Y.rawX, Y.intervalX)
    tbl = equipercentile(ftX, ftY)
    resFrequencyEstimation(tbl, X.marginal, Y.marginal)
end

#-----------------
end # module
